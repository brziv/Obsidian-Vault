#theory 

Claude Shannon (1940s)
Mathematical study of the quantification, storage and communication of information.
	Information is about reducing uncertainty
	More information: predictable -> surprising
	Randomness (noise) increases uncertainty
	
Compression:
	Repetitions and patterns can be compressed
	Removing redundancy, or predictability
	-> Datamoshing

Communication:
	Removes uncertainty (less noise) for receivers

Entropy:
	More uncertain is more entropy
	Entropy is the potential information

[[Information]]
[[Cryptography]]
